{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Introduzione al Modello Lineare in Python"],"metadata":{"id":"1dKV6QbvHl8f"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"bTZPh6pkHUkR"},"outputs":[],"source":["# importiamo le librerie necessarie\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.linear_model import LinearRegression"]},{"cell_type":"markdown","source":["1. Generiamo dei dati che, _per definizione_, sono linearmente correlati, ovvero tali che:\n","\n","$$y = \\beta + \\alpha \\cdot x$$\n","\n","Per rendere il nostro dataset più realistico, i nostri dati saranno tali che:\n","\n","$$y = \\beta + \\alpha \\cdot x + \\varepsilon$$\n","\n","dove $\\varepsilon \\sim \\textit{N}(0, \\sigma)$"],"metadata":{"id":"4YqhB_jPYPDb"}},{"cell_type":"code","source":["# definiamo i coefficienti a piacere\n","alpha = 2\n","beta = 5\n","sigma = 1\n","n_points = 10\n","x_min = 0\n","x_max = 10\n","\n","# generiamo il dataset\n","x = np.linspace(x_min, x_max, n_points).reshape(-1, 1)\n","# equazione della retta (senza rumore nei dati)\n","y = beta + alpha * x\n","y += np.random.normal(0, sigma, size=(n_points, 1))"],"metadata":{"id":"BED8NgvAZfs0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# visualizziamo i dati con uno scatterplot (usando matplotlib)\n","plt.scatter(x, y, color=\"blue\")\n","plt.xlabel(\"x\")\n","plt.ylabel(\"y\")\n","plt.title(\"Dati linearmente correlati\")\n","plt.show()"],"metadata":{"id":"6Adzyb6jbF5V"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["2. Facciamo il fit di un modello lineare utilizzando la libreria `scikit-learn` e verifichiamo qualitativamente (graficamente) il modello imparato:\n","\n"],"metadata":{"id":"89VCsuZybVjj"}},{"cell_type":"code","source":["# inizializzazione del modello\n","model = LinearRegression()\n","# stima dei coefficienti con il metodo dei minimi quadrati (in automatico)\n","model.fit(x, y)\n","# guardiamo i parametri \"fittati\" dal modello\n","pred_alpha = model.coef_[0][0]\n","pred_beta = model.intercept_[0]\n","print(f\"(coefficiente angolare) alpha = {pred_alpha:.2f} (originale: {alpha})\")\n","print(f\"(intercetta) beta = {pred_beta:.2f} (originale: {beta})\")"],"metadata":{"id":"Bbm38B2XbpMp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# vediamo il modello dove mappa i dati originali\n","y_pred = model.predict(x)\n","\n","# visualizziamo nella stessa figura i dati originali con uno scatterplot e quelli predetti con un plot\n","plt.scatter(x, y, color=\"blue\", label=\"Dati reali\")\n","plt.plot(x, y_pred, color=\"red\", label=\"Retta predetta\")\n","plt.xlabel(\"x\")\n","plt.ylabel(\"y\")\n","plt.title(\"Modello lineare semplice\")\n","plt.legend()\n","plt.show()"],"metadata":{"id":"nj9ZW49Pg6CZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["3. Esploriamo a bontà del modello tramite il coefficiente di determinazione $R^2$.\n","\n","Adesso per ogni dato valore di $x$ (variabile indipendente), il modello lineare ci restituisce:\n","\n","$$\\hat{y} = \\alpha \\cdot x + \\beta$$\n","\n","Supponendo di conoscere il _vero_ valore $y$ in corrispondenza di $x$, possiamo calcolare la differenza tra il valore $y$ e la previsione $\\hat{y}$:\n","\n","$$e = y - \\hat{y}$$\n","\n","e partire da questa differenza per valutare la bontà del modello lineare.\n","\n","**Coefficiente di determinazione**: $R^2$ varia tra 0 (pessimo) e 1 (ottimo) e indica la quantità di variabilità nei dati spiegata dal modello!\n","\n","Total Sum of Squares (TSS), i.e. varianza totale nei dati:\n","\n","$$TSS = \\sum_{i=1}^n (y_i - \\bar{y})^2$$\n","\n","Residual Sum of Squares (RSS), i.e. varianza residua nei dati alla luce del modello:\n","\n","$$RSS = \\sum_{i=1}^n (y_i - \\hat{y}_i)^2$$"],"metadata":{"id":"n6ZrP7ohhhSu"}},{"cell_type":"code","source":["r2 = model.score(x, y)\n","print(f\"Coefficiente di determinazione: {r2:.2f}\")"],"metadata":{"id":"p2VEx0hehQCB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Modello lineare interattivo\n","\n","Osserviamo cosa succede quando modifichiamo i parametri delle funzioni usate in precedenza:"],"metadata":{"id":"bVwHC6LTiLG5"}},{"cell_type":"code","source":["from ipywidgets import interact, FloatSlider, IntSlider\n","\n","def linear_model(beta=5.0, alpha=2.0, sigma=2.0, n_points=50):\n","    np.random.seed(42)\n","    x = np.linspace(0, 10, n_points).reshape(-1, 1)\n","    y = alpha * x + beta + np.random.normal(0, sigma, size=(n_points,1))\n","\n","    model = LinearRegression()\n","    model.fit(x, y)\n","    y_pred = model.predict(x)\n","    r2 = model.score(x, y)\n","\n","    plt.figure(figsize=(8,5))\n","    plt.scatter(x, y, color=\"blue\", label=\"Dati reali\")\n","    plt.plot(x, y_pred, color=\"red\", label=\"Retta predetta\")\n","    plt.xlabel(\"x\")\n","    plt.ylabel(\"y\")\n","    plt.title(f\"Modello lineare semplice\\nPendenza stimata={model.coef_[0][0]:.2f}, Intercetta stimata={model.intercept_[0]:.2f}, R^2={r2:.2f}\")\n","    plt.legend()\n","    plt.show()\n","\n","interact(linear_model,\n","         beta=FloatSlider(min=-10, max=10, step=0.5, value=5, description=\"Intercetta\"),\n","         alpha=FloatSlider(min=-5, max=5, step=0.1, value=2, description=\"Coefficiente Angolare\"),\n","         sigma=FloatSlider(min=0, max=5, step=0.1, value=2, description=\"Rumore nelle osservazioni\"),\n","         n_points=IntSlider(min=10, max=200, step=10, value=50, description=\"Numero di punti osservati\")\n","        );"],"metadata":{"id":"LUFpMWvOh1PF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["[Guess the Correlation!](https://www.guessthecorrelation.com)"],"metadata":{"id":"x0PEIyQzDy9-"}}]}